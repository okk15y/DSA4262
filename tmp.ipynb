{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions For Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "def load_json_gz_to_dataframe(file_path):\n",
    "    \"\"\"\n",
    "    Load gzipped JSON data into a DataFrame.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            json_data = json.loads(line)\n",
    "            for transcript, positions in json_data.items():\n",
    "                for position, sequences in positions.items():\n",
    "                    position = int(position)\n",
    "                    for sequence, reads in sequences.items():\n",
    "                        data.append({\n",
    "                            'transcript_id': transcript,\n",
    "                            'position': position,\n",
    "                            'sequence': sequence,\n",
    "                            'reads': reads\n",
    "                        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_mean_reads(dataset):\n",
    "    \"\"\"\n",
    "    Compute the mean of 'reads' for each row.\n",
    "    \"\"\"\n",
    "    dataset['mean_reads'] = dataset['reads'].apply(lambda x: np.mean(x, axis=0))\n",
    "    return dataset\n",
    "\n",
    "def scale_mean_reads(dataset, scaler=None, scaler_path='mean_reads_scaler.pkl'):\n",
    "    \"\"\"\n",
    "    Scale the 'mean_reads' column using StandardScaler.\n",
    "    \"\"\"\n",
    "    if scaler is None: # If no scaler is provided, fit a new one and save it\n",
    "        scaler = StandardScaler()\n",
    "        scaled_mean_reads = scaler.fit_transform(np.vstack(dataset['mean_reads'].values))\n",
    "        dataset['scaled_mean_reads'] = list(scaled_mean_reads)\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        print('Scaler saved to', scaler_path)\n",
    "    else: # Use the provided scaler to transform the data\n",
    "        scaled_mean_reads = scaler.transform(np.vstack(dataset['mean_reads'].values))\n",
    "        dataset['scaled_mean_reads'] = list(scaled_mean_reads)\n",
    "    return dataset\n",
    "\n",
    "def load_scaler(scaler_path='mean_reads_scaler.pkl'):\n",
    "    \"\"\"\n",
    "    Load the saved scaler from the given path.\n",
    "    \"\"\"\n",
    "    return joblib.load(scaler_path)\n",
    "\n",
    "def drach_encoder():\n",
    "    \"\"\"\n",
    "    Return a OneHotEncoder object with predefined DRACH motifs.\n",
    "    \"\"\"\n",
    "    # Define DRACH motifs to be used for one-hot encoding\n",
    "    D, R, A, C, H = ['A', 'G', 'T'], ['A', 'G'], ['A'], ['C'], ['A', 'C', 'T']\n",
    "    drach_motifs = [d + r + a + c + h for d in D for r in R for a in A for c in C for h in H]\n",
    "    encoder = OneHotEncoder(categories=[drach_motifs], handle_unknown='ignore')\n",
    "    return encoder\n",
    "\n",
    "def extract_middle_sequence(dataset):\n",
    "    \"\"\"\n",
    "    Extract the middle 5-mers sequence from the 'sequence' column.\n",
    "    \"\"\"\n",
    "    dataset['middle_sequence'] = dataset['sequence'].apply(lambda x: x[1:-1])\n",
    "    return dataset\n",
    "\n",
    "def one_hot_encode_DRACH(dataset, encoder=None, encoder_path='drach_encoder.pkl'):\n",
    "    \"\"\"\n",
    "    Apply one-hot encoding to the middle 5-mers sequence\n",
    "    \"\"\"\n",
    "    # One-hot encode the middle sequence\n",
    "    if encoder is None: # If no encoder is provided, fit a new one and save it\n",
    "        encoder = drach_encoder()\n",
    "        one_hot_matrix = encoder.fit_transform(dataset[['middle_sequence']])\n",
    "        joblib.dump(encoder, encoder_path)\n",
    "        print('DRACH Encoder saved to', encoder_path)\n",
    "    else:\n",
    "        one_hot_matrix = encoder.transform(dataset[['middle_sequence']])\n",
    "    dataset['middle_sequence_OHE'] = list(one_hot_matrix.toarray())\n",
    "    return dataset\n",
    "\n",
    "def load_DRACH_encoder(encoder_path='drach_encoder.pkl'):\n",
    "    \"\"\"\n",
    "    Load the saved DRACH encoder from the given path.\n",
    "    \"\"\"\n",
    "    return joblib.load(encoder_path)\n",
    "\n",
    "def combine_data(dataset, labels):\n",
    "    \"\"\"\n",
    "    Combine dataset with labels\n",
    "    \"\"\"\n",
    "    # Left join dataset with labels on 'transcript_id' and 'position'\n",
    "    merged_df = pd.merge(dataset, labels,\n",
    "                         left_on=['transcript_id', 'position'],\n",
    "                         right_on=['transcript_id', 'transcript_position'],\n",
    "                         how='left')\n",
    "    # Reorder gene_id to the first column and drop duplicate columns\n",
    "    gene_id = merged_df['gene_id']\n",
    "    merged_df = merged_df.drop(columns=['transcript_position', 'gene_id'])\n",
    "    merged_df.insert(0, 'gene_id', gene_id)\n",
    "    return merged_df\n",
    "\n",
    "def prepare_for_model(dataset):\n",
    "    \"\"\"\n",
    "    Combine 'scaled_mean_reads' and `middle_sequence_OHE` for model input.\n",
    "    \"\"\"\n",
    "    combined_features = np.hstack([np.vstack(dataset['scaled_mean_reads']), np.vstack(dataset['middle_sequence_OHE'])])\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene_id    transcript_id  transcript_position  label\n",
       "0  ENSG00000004059  ENST00000000233                  244      0\n",
       "1  ENSG00000004059  ENST00000000233                  261      0\n",
       "2  ENSG00000004059  ENST00000000233                  316      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('data.info.labelled')\n",
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>reads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>[[0.00299, 2.06, 125.0, 0.0177, 10.4, 122.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>CAAACTG</td>\n",
       "      <td>[[0.0126, 1.95, 111.0, 0.0125, 1.27, 108.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>GAAACAG</td>\n",
       "      <td>[[0.00432, 2.02, 104.0, 0.00299, 3.56, 99.3, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transcript_id  position sequence  \\\n",
       "0  ENST00000000233       244  AAGACCA   \n",
       "1  ENST00000000233       261  CAAACTG   \n",
       "2  ENST00000000233       316  GAAACAG   \n",
       "\n",
       "                                               reads  \n",
       "0  [[0.00299, 2.06, 125.0, 0.0177, 10.4, 122.0, 0...  \n",
       "1  [[0.0126, 1.95, 111.0, 0.0125, 1.27, 108.0, 0....  \n",
       "2  [[0.00432, 2.02, 104.0, 0.00299, 3.56, 99.3, 0...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_json_gz_to_dataframe('dataset0.json.gz')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign labels to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>reads</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>[[0.00299, 2.06, 125.0, 0.0177, 10.4, 122.0, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>CAAACTG</td>\n",
       "      <td>[[0.0126, 1.95, 111.0, 0.0125, 1.27, 108.0, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>GAAACAG</td>\n",
       "      <td>[[0.00432, 2.02, 104.0, 0.00299, 3.56, 99.3, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene_id    transcript_id  position sequence  \\\n",
       "0  ENSG00000004059  ENST00000000233       244  AAGACCA   \n",
       "1  ENSG00000004059  ENST00000000233       261  CAAACTG   \n",
       "2  ENSG00000004059  ENST00000000233       316  GAAACAG   \n",
       "\n",
       "                                               reads  label  \n",
       "0  [[0.00299, 2.06, 125.0, 0.0177, 10.4, 122.0, 0...      0  \n",
       "1  [[0.0126, 1.95, 111.0, 0.0125, 1.27, 108.0, 0....      0  \n",
       "2  [[0.00432, 2.02, 104.0, 0.00299, 3.56, 99.3, 0...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combine_data(df, labels)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract mean reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>reads</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_reads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>[[0.00299, 2.06, 125.0, 0.0177, 10.4, 122.0, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.008264378378378385, 4.223783783783786, 123....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>CAAACTG</td>\n",
       "      <td>[[0.0126, 1.95, 111.0, 0.0125, 1.27, 108.0, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.006609244186046515, 3.2164244186046504, 109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>GAAACAG</td>\n",
       "      <td>[[0.00432, 2.02, 104.0, 0.00299, 3.56, 99.3, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0075699999999999995, 2.94054054054054, 105....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene_id    transcript_id  position sequence  \\\n",
       "0  ENSG00000004059  ENST00000000233       244  AAGACCA   \n",
       "1  ENSG00000004059  ENST00000000233       261  CAAACTG   \n",
       "2  ENSG00000004059  ENST00000000233       316  GAAACAG   \n",
       "\n",
       "                                               reads  label  \\\n",
       "0  [[0.00299, 2.06, 125.0, 0.0177, 10.4, 122.0, 0...      0   \n",
       "1  [[0.0126, 1.95, 111.0, 0.0125, 1.27, 108.0, 0....      0   \n",
       "2  [[0.00432, 2.02, 104.0, 0.00299, 3.56, 99.3, 0...      0   \n",
       "\n",
       "                                          mean_reads  \n",
       "0  [0.008264378378378385, 4.223783783783786, 123....  \n",
       "1  [0.006609244186046515, 3.2164244186046504, 109...  \n",
       "2  [0.0075699999999999995, 2.94054054054054, 105....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_mean_reads(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split by gene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split by gene id\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_gene_ids, test_gene_ids = train_test_split(df['gene_id'].unique(), test_size=0.2, random_state=4262)\n",
    "\n",
    "train_df = df[df['gene_id'].isin(train_gene_ids)].copy()\n",
    "test_df = df[df['gene_id'].isin(test_gene_ids)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale mean reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to mean_reads_scaler.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>reads</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_reads</th>\n",
       "      <th>scaled_mean_reads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>355</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>[[0.00232, 2.41, 109.0, 0.0222, 2.85, 111.0, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.007340399999999998, 2.9771799999999997, 108...</td>\n",
       "      <td>[-0.43079389735504386, -0.7090163040809951, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>367</td>\n",
       "      <td>GGGACCG</td>\n",
       "      <td>[[0.00232, 1.32, 117.0, 0.0073, 7.89, 120.0, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.00898787234042553, 3.961489361702128, 118.6...</td>\n",
       "      <td>[0.49106279705280276, -0.1994143266757514, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>496</td>\n",
       "      <td>AGGACTG</td>\n",
       "      <td>[[0.00398, 2.46, 111.0, 0.016, 3.36, 125.0, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.011064705882352935, 7.299607843137254, 115....</td>\n",
       "      <td>[1.6531720821786586, 1.5288144651450055, 0.418...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene_id    transcript_id  position sequence  \\\n",
       "18  ENSG00000003056  ENST00000000412       355  GAAACTA   \n",
       "19  ENSG00000003056  ENST00000000412       367  GGGACCG   \n",
       "20  ENSG00000003056  ENST00000000412       496  AGGACTG   \n",
       "\n",
       "                                                reads  label  \\\n",
       "18  [[0.00232, 2.41, 109.0, 0.0222, 2.85, 111.0, 0...      0   \n",
       "19  [[0.00232, 1.32, 117.0, 0.0073, 7.89, 120.0, 0...      0   \n",
       "20  [[0.00398, 2.46, 111.0, 0.016, 3.36, 125.0, 0....      0   \n",
       "\n",
       "                                           mean_reads  \\\n",
       "18  [0.007340399999999998, 2.9771799999999997, 108...   \n",
       "19  [0.00898787234042553, 3.961489361702128, 118.6...   \n",
       "20  [0.011064705882352935, 7.299607843137254, 115....   \n",
       "\n",
       "                                    scaled_mean_reads  \n",
       "18  [-0.43079389735504386, -0.7090163040809951, -0...  \n",
       "19  [0.49106279705280276, -0.1994143266757514, 0.6...  \n",
       "20  [1.6531720821786586, 1.5288144651450055, 0.418...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale mean reads of train data first\n",
    "train_df = scale_mean_reads(train_df)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved scaler to transform the test data\n",
    "scaler = load_scaler()\n",
    "test_df = scale_mean_reads(test_df, scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract middle sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>reads</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_reads</th>\n",
       "      <th>scaled_mean_reads</th>\n",
       "      <th>middle_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>355</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>[[0.00232, 2.41, 109.0, 0.0222, 2.85, 111.0, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.007340399999999998, 2.9771799999999997, 108...</td>\n",
       "      <td>[-0.43079389735504386, -0.7090163040809951, -0...</td>\n",
       "      <td>AAACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>367</td>\n",
       "      <td>GGGACCG</td>\n",
       "      <td>[[0.00232, 1.32, 117.0, 0.0073, 7.89, 120.0, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.00898787234042553, 3.961489361702128, 118.6...</td>\n",
       "      <td>[0.49106279705280276, -0.1994143266757514, 0.6...</td>\n",
       "      <td>GGACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>496</td>\n",
       "      <td>AGGACTG</td>\n",
       "      <td>[[0.00398, 2.46, 111.0, 0.016, 3.36, 125.0, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.011064705882352935, 7.299607843137254, 115....</td>\n",
       "      <td>[1.6531720821786586, 1.5288144651450055, 0.418...</td>\n",
       "      <td>GGACT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene_id    transcript_id  position sequence  \\\n",
       "18  ENSG00000003056  ENST00000000412       355  GAAACTA   \n",
       "19  ENSG00000003056  ENST00000000412       367  GGGACCG   \n",
       "20  ENSG00000003056  ENST00000000412       496  AGGACTG   \n",
       "\n",
       "                                                reads  label  \\\n",
       "18  [[0.00232, 2.41, 109.0, 0.0222, 2.85, 111.0, 0...      0   \n",
       "19  [[0.00232, 1.32, 117.0, 0.0073, 7.89, 120.0, 0...      0   \n",
       "20  [[0.00398, 2.46, 111.0, 0.016, 3.36, 125.0, 0....      0   \n",
       "\n",
       "                                           mean_reads  \\\n",
       "18  [0.007340399999999998, 2.9771799999999997, 108...   \n",
       "19  [0.00898787234042553, 3.961489361702128, 118.6...   \n",
       "20  [0.011064705882352935, 7.299607843137254, 115....   \n",
       "\n",
       "                                    scaled_mean_reads middle_sequence  \n",
       "18  [-0.43079389735504386, -0.7090163040809951, -0...           AAACT  \n",
       "19  [0.49106279705280276, -0.1994143266757514, 0.6...           GGACC  \n",
       "20  [1.6531720821786586, 1.5288144651450055, 0.418...           GGACT  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = extract_middle_sequence(train_df)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = extract_middle_sequence(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode middle sequence (DRACH motif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRACH Encoder saved to drach_encoder.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>reads</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_reads</th>\n",
       "      <th>scaled_mean_reads</th>\n",
       "      <th>middle_sequence</th>\n",
       "      <th>middle_sequence_OHE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>355</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>[[0.00232, 2.41, 109.0, 0.0222, 2.85, 111.0, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.007340399999999998, 2.9771799999999997, 108...</td>\n",
       "      <td>[-0.43079389735504386, -0.7090163040809951, -0...</td>\n",
       "      <td>AAACT</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>367</td>\n",
       "      <td>GGGACCG</td>\n",
       "      <td>[[0.00232, 1.32, 117.0, 0.0073, 7.89, 120.0, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.00898787234042553, 3.961489361702128, 118.6...</td>\n",
       "      <td>[0.49106279705280276, -0.1994143266757514, 0.6...</td>\n",
       "      <td>GGACC</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>496</td>\n",
       "      <td>AGGACTG</td>\n",
       "      <td>[[0.00398, 2.46, 111.0, 0.016, 3.36, 125.0, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.011064705882352935, 7.299607843137254, 115....</td>\n",
       "      <td>[1.6531720821786586, 1.5288144651450055, 0.418...</td>\n",
       "      <td>GGACT</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene_id    transcript_id  position sequence  \\\n",
       "18  ENSG00000003056  ENST00000000412       355  GAAACTA   \n",
       "19  ENSG00000003056  ENST00000000412       367  GGGACCG   \n",
       "20  ENSG00000003056  ENST00000000412       496  AGGACTG   \n",
       "\n",
       "                                                reads  label  \\\n",
       "18  [[0.00232, 2.41, 109.0, 0.0222, 2.85, 111.0, 0...      0   \n",
       "19  [[0.00232, 1.32, 117.0, 0.0073, 7.89, 120.0, 0...      0   \n",
       "20  [[0.00398, 2.46, 111.0, 0.016, 3.36, 125.0, 0....      0   \n",
       "\n",
       "                                           mean_reads  \\\n",
       "18  [0.007340399999999998, 2.9771799999999997, 108...   \n",
       "19  [0.00898787234042553, 3.961489361702128, 118.6...   \n",
       "20  [0.011064705882352935, 7.299607843137254, 115....   \n",
       "\n",
       "                                    scaled_mean_reads middle_sequence  \\\n",
       "18  [-0.43079389735504386, -0.7090163040809951, -0...           AAACT   \n",
       "19  [0.49106279705280276, -0.1994143266757514, 0.6...           GGACC   \n",
       "20  [1.6531720821786586, 1.5288144651450055, 0.418...           GGACT   \n",
       "\n",
       "                                  middle_sequence_OHE  \n",
       "18  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "19  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "20  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = one_hot_encode_DRACH(train_df)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved DRACH encoder to transform the test data\n",
    "encoder = load_DRACH_encoder()\n",
    "test_df = one_hot_encode_DRACH(test_df, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check label imbalance (FOR SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04520309457830705"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels in the training set\n",
    "np.mean(train_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gene_id with no postive labels:  1885\n",
      "Proportion of gene_id with no positive labels:  0.6118143459915611\n"
     ]
    }
   ],
   "source": [
    "# Proportion of positive labels by gene_id\n",
    "prop_gene_id = train_df.groupby('gene_id')['label'].mean()\n",
    "\n",
    "# Number of zeros\n",
    "num_zeros = len(prop_gene_id[prop_gene_id == 0])\n",
    "print('Number of gene_id with no postive labels: ', num_zeros)\n",
    "print('Proportion of gene_id with no positive labels: ', num_zeros / len(prop_gene_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get the scaled mean reads and one-hot encoded middle sequence columns as dataframe\n",
    "X_resampled_list = [] \n",
    "y_resampled_list = []\n",
    "gene_id_list = []\n",
    "\n",
    "for g_id, group in train_df.groupby('gene_id'):\n",
    "    X = np.vstack(group['scaled_mean_reads'].values)\n",
    "    y = group['label'].values\n",
    "    \n",
    "    if sum(y) < 10 or sum(y - 1) < 10:  # Skip resampling if the number of positive labels is less than 10\n",
    "        X_resampled_list.append(X)\n",
    "        y_resampled_list.append(y)\n",
    "        gene_id_list.extend([g_id] * len(y))  # Use g_id for the gene_id\n",
    "        continue\n",
    "\n",
    "    # Apply SMOTE to the scaled mean reads and labels\n",
    "    smote = SMOTE(random_state=4262)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    # Append resampled data to lists\n",
    "    X_resampled_list.append(X_resampled)\n",
    "    y_resampled_list.append(y_resampled)\n",
    "    gene_id_list.extend([g_id] * len(y_resampled))  # Use g_id for the gene_id\n",
    "\n",
    "# Combine all resampled data into final arrays\n",
    "X_resampled_gene = np.vstack(X_resampled_list)\n",
    "y_resampled_gene = np.concatenate(y_resampled_list)\n",
    "\n",
    "# Combine into a final DataFrame if needed\n",
    "resampled_gene_df = pd.DataFrame({\n",
    "    'scaled_mean_reads': list(X_resampled_gene),\n",
    "    'gene_id': gene_id_list,\n",
    "    'label': y_resampled_gene\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positive labels in the resampled data: 0.04520309457830705\n",
      "Number of gene_id with no postive labels:  1885\n",
      "Proportion of gene_id with no positive labels:  0.6118143459915611\n"
     ]
    }
   ],
   "source": [
    "# Proportion of positive labels in the resampled data\n",
    "print('Proportion of positive labels in the resampled data:', np.mean(resampled_gene_df['label']))\n",
    "\n",
    "# Proportion of positive labels by gene_id\n",
    "prop_gene_id = resampled_gene_df.groupby('gene_id')['label'].mean()\n",
    "\n",
    "# Number of zeros\n",
    "num_zeros = len(prop_gene_id[prop_gene_id == 0])\n",
    "print('Number of gene_id with no postive labels: ', num_zeros)\n",
    "print('Proportion of gene_id with no positive labels: ', num_zeros / len(prop_gene_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIDDLE_SEQUENCE (DRACH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DRACH motifs with no postive labels:  0\n",
      "Proportion of DRACH motifs with no positive labels:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Proportion of positive labels by middle_sequence\n",
    "prop_drach = train_df.groupby('middle_sequence')['label'].mean()\n",
    "\n",
    "# Number of zeros\n",
    "num_zeros = len(prop_drach[prop_drach == 0])\n",
    "print('Number of DRACH motifs with no postive labels: ', num_zeros)\n",
    "print('Proportion of DRACH motifs with no positive labels: ', num_zeros / len(prop_drach))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "middle_sequence\n",
       "TAACA       1\n",
       "TAACC       2\n",
       "AAACC      10\n",
       "AAACA      32\n",
       "AGACC      51\n",
       "TAACT      53\n",
       "TGACA      59\n",
       "TGACC      79\n",
       "GAACC      95\n",
       "AGACA     111\n",
       "GAACA     136\n",
       "AAACT     209\n",
       "TGACT     355\n",
       "GGACC     417\n",
       "AGACT     429\n",
       "GGACA     550\n",
       "GAACT     653\n",
       "GGACT    1146\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of positive labels by middle_sequence\n",
    "train_df[train_df['label'] == 1].groupby('middle_sequence')['label'].count().sort_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SMOTE to each group of DRACH motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Get the scaled mean reads and one-hot encoded middle sequence columns as dataframe\n",
    "X_resampled_list = [] \n",
    "y_resampled_list = []\n",
    "middle_sequence_list = []\n",
    "\n",
    "for middle_seq, group in train_df.groupby('middle_sequence'):\n",
    "    X = np.vstack(group['scaled_mean_reads'].values)\n",
    "    y = group['label'].values\n",
    "    \n",
    "    if sum(y) < 10: # Skip if the number of positive labels is less than 10\n",
    "        X_resampled_list.append(X)\n",
    "        y_resampled_list.append(y)\n",
    "        middle_sequence_list.extend([middle_seq] * len(y))\n",
    "        continue\n",
    "\n",
    "    # Apply SMOTE to the scaled mean reads and labels\n",
    "    smote = SMOTE(random_state=4262)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    # Append resampled data and one-hot encoding to lists\n",
    "    X_resampled_list.append(X_resampled)\n",
    "    y_resampled_list.append(y_resampled)\n",
    "    middle_sequence_list.extend([middle_seq] * len(y_resampled))\n",
    "\n",
    "# Combine all resampled data into final arrays\n",
    "X_resampled = np.vstack(X_resampled_list)\n",
    "y_resampled = np.concatenate(y_resampled_list)\n",
    "\n",
    "# Combine into a final DataFrame if needed\n",
    "resampled_df = pd.DataFrame({\n",
    "    'scaled_mean_reads': list(X_resampled),\n",
    "    'middle_sequence': middle_sequence_list,\n",
    "    'label': y_resampled\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positive labels in the resampled data:  0.483202765619337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "middle_sequence\n",
       "AAACA    0.500000\n",
       "AAACC    0.500000\n",
       "AAACT    0.500000\n",
       "AGACA    0.500000\n",
       "AGACC    0.500000\n",
       "AGACT    0.500000\n",
       "GAACA    0.500000\n",
       "GAACC    0.500000\n",
       "GAACT    0.500000\n",
       "GGACA    0.500000\n",
       "GGACC    0.500000\n",
       "GGACT    0.500000\n",
       "TAACA    0.000271\n",
       "TAACC    0.000856\n",
       "TAACT    0.500000\n",
       "TGACA    0.500000\n",
       "TGACC    0.500000\n",
       "TGACT    0.500000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels in the resampled data\n",
    "print('Proportion of positive labels in the resampled data: ', np.mean(resampled_df['label']))\n",
    "\n",
    "# Proportion of positive labels by middle_sequence\n",
    "prop_drach_resampled = resampled_df.groupby('middle_sequence')['label'].mean()\n",
    "prop_drach_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode DRACH motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRACH Encoder saved to drach_encoder.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_mean_reads</th>\n",
       "      <th>middle_sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>middle_sequence_OHE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2.5249757619759317, -0.7835678231993425, -0.2...</td>\n",
       "      <td>AAACA</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.6928199968356539, -1.1676038905620205, -0.7...</td>\n",
       "      <td>AAACA</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.3732826597732115, -0.8372266235169966, -0.2...</td>\n",
       "      <td>AAACA</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   scaled_mean_reads middle_sequence  label  \\\n",
       "0  [2.5249757619759317, -0.7835678231993425, -0.2...           AAACA      0   \n",
       "1  [0.6928199968356539, -1.1676038905620205, -0.7...           AAACA      0   \n",
       "2  [0.3732826597732115, -0.8372266235169966, -0.2...           AAACA      0   \n",
       "\n",
       "                                 middle_sequence_OHE  \n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df = one_hot_encode_DRACH(resampled_df)\n",
    "resampled_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With SMOTE\n",
    "X_resampled = prepare_for_model(resampled_df)\n",
    "y_resampled = resampled_df['label'].values\n",
    "\n",
    "# Without SMOTE\n",
    "X_train = prepare_for_model(train_df)\n",
    "y_train = train_df['label'].values\n",
    "\n",
    "# Prepare test data\n",
    "X_test = prepare_for_model(test_df)\n",
    "y_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Define and compile neural network model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_shape,)),\n",
    "        Dense(150, activation='relu'),\n",
    "        Dropout(0.2),  # Dropout layer for regularization\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),  # Another dropout layer\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    # Set AUC with Precision-Recall (PR) curve\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(curve='PR', name='auc_pr')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with and without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1 with SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - auc_pr: 0.7317 - loss: 0.5755 - val_auc_pr: 0.8537 - val_loss: 0.4561\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - auc_pr: 0.8477 - loss: 0.4593 - val_auc_pr: 0.8810 - val_loss: 0.4146\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - auc_pr: 0.8703 - loss: 0.4248 - val_auc_pr: 0.8953 - val_loss: 0.3867\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - auc_pr: 0.8826 - loss: 0.4059 - val_auc_pr: 0.9083 - val_loss: 0.3652\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - auc_pr: 0.8925 - loss: 0.3866 - val_auc_pr: 0.9169 - val_loss: 0.3488\n",
      "Training fold 2 with SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - auc_pr: 0.7258 - loss: 0.5774 - val_auc_pr: 0.8540 - val_loss: 0.4572\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - auc_pr: 0.8402 - loss: 0.4671 - val_auc_pr: 0.8822 - val_loss: 0.4135\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - auc_pr: 0.8663 - loss: 0.4287 - val_auc_pr: 0.8966 - val_loss: 0.3842\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - auc_pr: 0.8762 - loss: 0.4108 - val_auc_pr: 0.9039 - val_loss: 0.3741\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - auc_pr: 0.8863 - loss: 0.3935 - val_auc_pr: 0.9136 - val_loss: 0.3526\n",
      "Training fold 3 with SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - auc_pr: 0.7294 - loss: 0.5765 - val_auc_pr: 0.8542 - val_loss: 0.4513\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - auc_pr: 0.8432 - loss: 0.4630 - val_auc_pr: 0.8814 - val_loss: 0.4092\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - auc_pr: 0.8694 - loss: 0.4252 - val_auc_pr: 0.8945 - val_loss: 0.3838\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - auc_pr: 0.8788 - loss: 0.4083 - val_auc_pr: 0.9078 - val_loss: 0.3563\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - auc_pr: 0.8898 - loss: 0.3883 - val_auc_pr: 0.9151 - val_loss: 0.3446\n",
      "Training fold 4 with SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - auc_pr: 0.7365 - loss: 0.5727 - val_auc_pr: 0.8597 - val_loss: 0.4483\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - auc_pr: 0.8431 - loss: 0.4618 - val_auc_pr: 0.8829 - val_loss: 0.4095\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - auc_pr: 0.8655 - loss: 0.4308 - val_auc_pr: 0.8963 - val_loss: 0.3854\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - auc_pr: 0.8801 - loss: 0.4081 - val_auc_pr: 0.9030 - val_loss: 0.3710\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - auc_pr: 0.8895 - loss: 0.3907 - val_auc_pr: 0.9144 - val_loss: 0.3522\n",
      "Training fold 5 with SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - auc_pr: 0.7242 - loss: 0.5810 - val_auc_pr: 0.8606 - val_loss: 0.4512\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - auc_pr: 0.8437 - loss: 0.4646 - val_auc_pr: 0.8768 - val_loss: 0.4167\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - auc_pr: 0.8664 - loss: 0.4316 - val_auc_pr: 0.8993 - val_loss: 0.3831\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - auc_pr: 0.8815 - loss: 0.4061 - val_auc_pr: 0.9090 - val_loss: 0.3642\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - auc_pr: 0.8897 - loss: 0.3921 - val_auc_pr: 0.9168 - val_loss: 0.3455\n",
      "Training fold 1 without SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc_pr: 0.1573 - loss: 0.1761 - val_auc_pr: 0.3803 - val_loss: 0.1307\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - auc_pr: 0.3491 - loss: 0.1342 - val_auc_pr: 0.4113 - val_loss: 0.1268\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.3806 - loss: 0.1331 - val_auc_pr: 0.4171 - val_loss: 0.1262\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.4086 - loss: 0.1283 - val_auc_pr: 0.4200 - val_loss: 0.1248\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.4098 - loss: 0.1314 - val_auc_pr: 0.4172 - val_loss: 0.1265\n",
      "Training fold 2 without SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc_pr: 0.1510 - loss: 0.1775 - val_auc_pr: 0.3796 - val_loss: 0.1326\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.3567 - loss: 0.1325 - val_auc_pr: 0.3953 - val_loss: 0.1302\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - auc_pr: 0.3714 - loss: 0.1334 - val_auc_pr: 0.4150 - val_loss: 0.1274\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.4029 - loss: 0.1324 - val_auc_pr: 0.4210 - val_loss: 0.1270\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - auc_pr: 0.4054 - loss: 0.1280 - val_auc_pr: 0.4206 - val_loss: 0.1255\n",
      "Training fold 3 without SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc_pr: 0.1973 - loss: 0.1659 - val_auc_pr: 0.3706 - val_loss: 0.1302\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - auc_pr: 0.3749 - loss: 0.1355 - val_auc_pr: 0.4009 - val_loss: 0.1246\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.4002 - loss: 0.1290 - val_auc_pr: 0.4131 - val_loss: 0.1217\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.4096 - loss: 0.1263 - val_auc_pr: 0.4053 - val_loss: 0.1226\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - auc_pr: 0.4173 - loss: 0.1263 - val_auc_pr: 0.4196 - val_loss: 0.1216\n",
      "Training fold 4 without SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc_pr: 0.1776 - loss: 0.1672 - val_auc_pr: 0.3780 - val_loss: 0.1273\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - auc_pr: 0.3818 - loss: 0.1346 - val_auc_pr: 0.3817 - val_loss: 0.1254\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - auc_pr: 0.4101 - loss: 0.1326 - val_auc_pr: 0.3994 - val_loss: 0.1224\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.4002 - loss: 0.1322 - val_auc_pr: 0.3909 - val_loss: 0.1230\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - auc_pr: 0.4239 - loss: 0.1279 - val_auc_pr: 0.3945 - val_loss: 0.1220\n",
      "Training fold 5 without SMOTE\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc_pr: 0.1571 - loss: 0.1717 - val_auc_pr: 0.4016 - val_loss: 0.1357\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - auc_pr: 0.3532 - loss: 0.1332 - val_auc_pr: 0.4170 - val_loss: 0.1344\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.3906 - loss: 0.1288 - val_auc_pr: 0.4245 - val_loss: 0.1326\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.3860 - loss: 0.1299 - val_auc_pr: 0.4409 - val_loss: 0.1310\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc_pr: 0.4088 - loss: 0.1285 - val_auc_pr: 0.4304 - val_loss: 0.1317\n",
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - auc_pr: 0.3240 - loss: 0.3765\n",
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_pr: 0.4534 - loss: 0.1150\n",
      "Test results with SMOTE: [0.3768007159233093, 0.3299456238746643]\n",
      "Test results without SMOTE: [0.11864431947469711, 0.4650230407714844]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=4262)\n",
    "best_val_auc_pr_smote = 0\n",
    "best_val_auc_pr_no_smote = 0\n",
    "best_model_path_smote = 'best_model_with_smote.keras'\n",
    "best_model_path_no_smote = 'best_model_without_smote.keras'\n",
    "\n",
    "# Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_resampled)):\n",
    "    print(f\"Training fold {fold + 1} with SMOTE\")\n",
    "\n",
    "    # Split the data with SMOTE for this fold\n",
    "    X_train_smote, X_val_smote = X_resampled[train_idx], X_resampled[val_idx]\n",
    "    y_train_smote, y_val_smote = y_resampled[train_idx], y_resampled[val_idx]\n",
    "\n",
    "    # Initialize and compile the model\n",
    "    model_smote = build_model(X_train_smote.shape[1])\n",
    "\n",
    "    # Set up the checkpoint to monitor AUC-PR and save the best model\n",
    "    checkpoint_smote = ModelCheckpoint(\n",
    "        best_model_path_smote,\n",
    "        save_best_only=True,\n",
    "        monitor='val_auc_pr',\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    # Train the model on this fold with SMOTE data\n",
    "    history_smote = model_smote.fit(\n",
    "        X_train_smote, y_train_smote,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val_smote, y_val_smote),\n",
    "        callbacks=[checkpoint_smote]\n",
    "    )\n",
    "\n",
    "    # Track the best validation AUC-PR across folds with SMOTE\n",
    "    fold_best_auc_pr_smote = max(history_smote.history['val_auc_pr'])\n",
    "    if fold_best_auc_pr_smote > best_val_auc_pr_smote:\n",
    "        best_val_auc_pr_smote = fold_best_auc_pr_smote\n",
    "\n",
    "# Cross-validation without SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold + 1} without SMOTE\")\n",
    "\n",
    "    # Split the data without SMOTE for this fold\n",
    "    X_train_no_smote, X_val_no_smote = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_no_smote, y_val_no_smote = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Initialize and compile the model\n",
    "    model_no_smote = build_model(X_train_no_smote.shape[1])\n",
    "\n",
    "    # Set up the checkpoint to monitor AUC-PR and save the best model\n",
    "    checkpoint_no_smote = ModelCheckpoint(\n",
    "        best_model_path_no_smote,\n",
    "        save_best_only=True,\n",
    "        monitor='val_auc_pr',\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    # Train the model on this fold without SMOTE data\n",
    "    history_no_smote = model_no_smote.fit(\n",
    "        X_train_no_smote, y_train_no_smote,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val_no_smote, y_val_no_smote),\n",
    "        callbacks=[checkpoint_no_smote]\n",
    "    )\n",
    "\n",
    "    # Track the best validation AUC-PR across folds without SMOTE\n",
    "    fold_best_auc_pr_no_smote = max(history_no_smote.history['val_auc_pr'])\n",
    "    if fold_best_auc_pr_no_smote > best_val_auc_pr_no_smote:\n",
    "        best_val_auc_pr_no_smote = fold_best_auc_pr_no_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Metrics Comparison on Test Data:\n",
      "\n",
      "With SMOTE:\n",
      "AUC-ROC: 0.8507\n",
      "AUC-PR: 0.3312\n",
      "Accuracy: 0.9564\n",
      "Average Precision Score: 0.3312\n",
      "\n",
      "Without SMOTE:\n",
      "AUC-ROC: 0.8907\n",
      "AUC-PR: 0.4660\n",
      "Accuracy: 0.9561\n",
      "Average Precision Score: 0.4660\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_recall_curve\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the best model for both SMOTE and no-SMOTE versions\n",
    "best_model_smote = load_model(best_model_path_smote)\n",
    "best_model_no_smote = load_model(best_model_path_no_smote)\n",
    "\n",
    "threshold = 0.9\n",
    "# Generate predictions and probabilities for both models on the test data\n",
    "y_pred_smote = (best_model_smote.predict(X_test) > threshold).astype(\"int32\").flatten()  # Binary predictions\n",
    "y_proba_smote = best_model_smote.predict(X_test).flatten()  # Probabilities\n",
    "\n",
    "y_pred_no_smote = (best_model_no_smote.predict(X_test) > threshold).astype(\"int32\").flatten()  # Binary predictions\n",
    "y_proba_no_smote = best_model_no_smote.predict(X_test).flatten()  # Probabilities\n",
    "\n",
    "# Calculate metrics for SMOTE model\n",
    "roc_auc_smote = roc_auc_score(y_test, y_proba_smote)\n",
    "pr_auc_smote = average_precision_score(y_test, y_proba_smote)  # AUC-PR\n",
    "accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "average_precision_smote = average_precision_score(y_test, y_proba_smote)\n",
    "\n",
    "# Calculate metrics for No-SMOTE model\n",
    "roc_auc_no_smote = roc_auc_score(y_test, y_proba_no_smote)\n",
    "pr_auc_no_smote = average_precision_score(y_test, y_proba_no_smote)  # AUC-PR\n",
    "accuracy_no_smote = accuracy_score(y_test, y_pred_no_smote)\n",
    "average_precision_no_smote = average_precision_score(y_test, y_proba_no_smote)\n",
    "\n",
    "# Print comparison results\n",
    "print(\"Metrics Comparison on Test Data:\")\n",
    "print(\"\\nWith SMOTE:\")\n",
    "print(f\"AUC-ROC: {roc_auc_smote:.4f}\")\n",
    "print(f\"AUC-PR: {pr_auc_smote:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_smote:.4f}\")\n",
    "print(f\"Average Precision Score: {average_precision_smote:.4f}\")\n",
    "\n",
    "print(\"\\nWithout SMOTE:\")\n",
    "print(f\"AUC-ROC: {roc_auc_no_smote:.4f}\")\n",
    "print(f\"AUC-PR: {pr_auc_no_smote:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_no_smote:.4f}\")\n",
    "print(f\"Average Precision Score: {average_precision_no_smote:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN model Regularisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Define and compile neural network model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_shape,)),\n",
    "        Dense(150, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),  # Dropout layer for regularization\n",
    "        Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),  # Another dropout layer\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    # Set AUC with Precision-Recall (PR) curve\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(curve='PR', name='auc_pr')])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with L2 regulariser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1 with SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - auc_pr: 0.6786 - loss: 0.7453 - val_auc_pr: 0.7800 - val_loss: 0.5972\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7715 - loss: 0.5990 - val_auc_pr: 0.7986 - val_loss: 0.5802\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7904 - loss: 0.5812 - val_auc_pr: 0.8123 - val_loss: 0.5604\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7994 - loss: 0.5677 - val_auc_pr: 0.8213 - val_loss: 0.5487\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.8062 - loss: 0.5596 - val_auc_pr: 0.8315 - val_loss: 0.5467\n",
      "Training fold 2 with SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - auc_pr: 0.6853 - loss: 0.7513 - val_auc_pr: 0.7814 - val_loss: 0.6083\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7726 - loss: 0.5977 - val_auc_pr: 0.8065 - val_loss: 0.5687\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7852 - loss: 0.5802 - val_auc_pr: 0.8204 - val_loss: 0.5598\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7982 - loss: 0.5675 - val_auc_pr: 0.8275 - val_loss: 0.5481\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.8047 - loss: 0.5595 - val_auc_pr: 0.8285 - val_loss: 0.5473\n",
      "Training fold 3 with SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - auc_pr: 0.6816 - loss: 0.7393 - val_auc_pr: 0.7809 - val_loss: 0.6005\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7711 - loss: 0.5983 - val_auc_pr: 0.8096 - val_loss: 0.5740\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7895 - loss: 0.5802 - val_auc_pr: 0.8131 - val_loss: 0.5557\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7953 - loss: 0.5719 - val_auc_pr: 0.8185 - val_loss: 0.5513\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.8035 - loss: 0.5625 - val_auc_pr: 0.8235 - val_loss: 0.5416\n",
      "Training fold 4 with SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - auc_pr: 0.6829 - loss: 0.7544 - val_auc_pr: 0.7924 - val_loss: 0.5913\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7705 - loss: 0.6006 - val_auc_pr: 0.8084 - val_loss: 0.5713\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - auc_pr: 0.7898 - loss: 0.5802 - val_auc_pr: 0.8198 - val_loss: 0.5568\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7985 - loss: 0.5693 - val_auc_pr: 0.8205 - val_loss: 0.5461\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.8054 - loss: 0.5622 - val_auc_pr: 0.8242 - val_loss: 0.5431\n",
      "Training fold 5 with SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - auc_pr: 0.6808 - loss: 0.7429 - val_auc_pr: 0.7991 - val_loss: 0.5871\n",
      "Epoch 2/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7706 - loss: 0.5983 - val_auc_pr: 0.8124 - val_loss: 0.5706\n",
      "Epoch 3/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7877 - loss: 0.5800 - val_auc_pr: 0.8273 - val_loss: 0.5520\n",
      "Epoch 4/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.7976 - loss: 0.5685 - val_auc_pr: 0.8322 - val_loss: 0.5466\n",
      "Epoch 5/5\n",
      "\u001b[1m4484/4484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - auc_pr: 0.8054 - loss: 0.5616 - val_auc_pr: 0.8289 - val_loss: 0.5450\n",
      "Training fold 1 without SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - auc_pr: 0.1182 - loss: 0.3328 - val_auc_pr: 0.1782 - val_loss: 0.1774\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1763 - loss: 0.1803 - val_auc_pr: 0.2558 - val_loss: 0.1726\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2188 - loss: 0.1728 - val_auc_pr: 0.2960 - val_loss: 0.1657\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2863 - loss: 0.1678 - val_auc_pr: 0.3229 - val_loss: 0.1614\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2972 - loss: 0.1662 - val_auc_pr: 0.3570 - val_loss: 0.1569\n",
      "Training fold 2 without SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - auc_pr: 0.0932 - loss: 0.3670 - val_auc_pr: 0.1480 - val_loss: 0.1792\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1246 - loss: 0.1799 - val_auc_pr: 0.1873 - val_loss: 0.1754\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1772 - loss: 0.1788 - val_auc_pr: 0.2722 - val_loss: 0.1708\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2261 - loss: 0.1714 - val_auc_pr: 0.3154 - val_loss: 0.1646\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2474 - loss: 0.1637 - val_auc_pr: 0.3359 - val_loss: 0.1605\n",
      "Training fold 3 without SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - auc_pr: 0.0922 - loss: 0.3615 - val_auc_pr: 0.1324 - val_loss: 0.1745\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1301 - loss: 0.1827 - val_auc_pr: 0.1812 - val_loss: 0.1716\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1904 - loss: 0.1783 - val_auc_pr: 0.2289 - val_loss: 0.1642\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2360 - loss: 0.1750 - val_auc_pr: 0.2511 - val_loss: 0.1617\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2679 - loss: 0.1695 - val_auc_pr: 0.3033 - val_loss: 0.1561\n",
      "Training fold 4 without SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - auc_pr: 0.0933 - loss: 0.3717 - val_auc_pr: 0.1688 - val_loss: 0.1734\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1208 - loss: 0.1777 - val_auc_pr: 0.2240 - val_loss: 0.1684\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1921 - loss: 0.1777 - val_auc_pr: 0.2612 - val_loss: 0.1644\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2519 - loss: 0.1694 - val_auc_pr: 0.3101 - val_loss: 0.1622\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2745 - loss: 0.1661 - val_auc_pr: 0.3084 - val_loss: 0.1562\n",
      "Training fold 5 without SMOTE + L2\n",
      "Epoch 1/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - auc_pr: 0.0930 - loss: 0.3572 - val_auc_pr: 0.1782 - val_loss: 0.1841\n",
      "Epoch 2/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1223 - loss: 0.1737 - val_auc_pr: 0.2510 - val_loss: 0.1783\n",
      "Epoch 3/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.1921 - loss: 0.1771 - val_auc_pr: 0.2889 - val_loss: 0.1730\n",
      "Epoch 4/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2210 - loss: 0.1663 - val_auc_pr: 0.3374 - val_loss: 0.1683\n",
      "Epoch 5/5\n",
      "\u001b[1m2427/2427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_pr: 0.2530 - loss: 0.1636 - val_auc_pr: 0.3401 - val_loss: 0.1675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=4262)\n",
    "best_val_auc_pr_smote = 0\n",
    "best_val_auc_pr_no_smote = 0\n",
    "best_model_path_smote_L2 = 'best_model_with_smote_L2.keras'\n",
    "best_model_path_no_smote_L2 = 'best_model_without_smote_L2.keras'\n",
    "\n",
    "# Cross-validation with SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_resampled)):\n",
    "    print(f\"Training fold {fold + 1} with SMOTE + L2\")\n",
    "\n",
    "    # Split the data with SMOTE for this fold\n",
    "    X_train_smote, X_val_smote = X_resampled[train_idx], X_resampled[val_idx]\n",
    "    y_train_smote, y_val_smote = y_resampled[train_idx], y_resampled[val_idx]\n",
    "\n",
    "    # Initialize and compile the model\n",
    "    model_smote = build_model(X_train_smote.shape[1])\n",
    "\n",
    "    # Set up the checkpoint to monitor AUC-PR and save the best model\n",
    "    checkpoint_smote = ModelCheckpoint(\n",
    "        best_model_path_smote,\n",
    "        save_best_only=True,\n",
    "        monitor='val_auc_pr',\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    # Train the model on this fold with SMOTE data\n",
    "    history_smote = model_smote.fit(\n",
    "        X_train_smote, y_train_smote,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val_smote, y_val_smote),\n",
    "        callbacks=[checkpoint_smote]\n",
    "    )\n",
    "\n",
    "    # Track the best validation AUC-PR across folds with SMOTE\n",
    "    fold_best_auc_pr_smote = max(history_smote.history['val_auc_pr'])\n",
    "    if fold_best_auc_pr_smote > best_val_auc_pr_smote:\n",
    "        best_val_auc_pr_smote = fold_best_auc_pr_smote\n",
    "\n",
    "# Cross-validation without SMOTE\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold + 1} without SMOTE + L2\")\n",
    "\n",
    "    # Split the data without SMOTE for this fold\n",
    "    X_train_no_smote, X_val_no_smote = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_no_smote, y_val_no_smote = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Initialize and compile the model\n",
    "    model_no_smote = build_model(X_train_no_smote.shape[1])\n",
    "\n",
    "    # Set up the checkpoint to monitor AUC-PR and save the best model\n",
    "    checkpoint_no_smote = ModelCheckpoint(\n",
    "        best_model_path_no_smote,\n",
    "        save_best_only=True,\n",
    "        monitor='val_auc_pr',\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    # Train the model on this fold without SMOTE data\n",
    "    history_no_smote = model_no_smote.fit(\n",
    "        X_train_no_smote, y_train_no_smote,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val_no_smote, y_val_no_smote),\n",
    "        callbacks=[checkpoint_no_smote]\n",
    "    )\n",
    "\n",
    "    # Track the best validation AUC-PR across folds without SMOTE\n",
    "    fold_best_auc_pr_no_smote = max(history_no_smote.history['val_auc_pr'])\n",
    "    if fold_best_auc_pr_no_smote > best_val_auc_pr_no_smote:\n",
    "        best_val_auc_pr_no_smote = fold_best_auc_pr_no_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m774/774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Metrics Comparison on Test Data:\n",
      "\n",
      "With SMOTE + Focal Loss:\n",
      "AUC-ROC: 0.8080\n",
      "AUC-PR: 0.2868\n",
      "Accuracy: 0.9566\n",
      "Average Precision Score: 0.2868\n",
      "\n",
      "Without SMOTE + Focal Loss:\n",
      "AUC-ROC: 0.8543\n",
      "AUC-PR: 0.3406\n",
      "Accuracy: 0.9561\n",
      "Average Precision Score: 0.3406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_recall_curve\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the best model for both SMOTE and no-SMOTE versions\n",
    "best_model_smote = load_model(\"best_model_with_smote.keras\")\n",
    "best_model_no_smote = load_model(\"best_model_without_smote.keras\")\n",
    "\n",
    "threshold = 0.9\n",
    "# Generate predictions and probabilities for both models on the test data\n",
    "y_pred_smote = (best_model_smote.predict(X_test) > threshold).astype(\"int32\").flatten()  # Binary predictions\n",
    "y_proba_smote = best_model_smote.predict(X_test).flatten()  # Probabilities\n",
    "\n",
    "y_pred_no_smote = (best_model_no_smote.predict(X_test) > threshold).astype(\"int32\").flatten()  # Binary predictions\n",
    "y_proba_no_smote = best_model_no_smote.predict(X_test).flatten()  # Probabilities\n",
    "\n",
    "# Calculate metrics for SMOTE model\n",
    "roc_auc_smote = roc_auc_score(y_test, y_proba_smote)\n",
    "pr_auc_smote = average_precision_score(y_test, y_proba_smote)  # AUC-PR\n",
    "accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "average_precision_smote = average_precision_score(y_test, y_proba_smote)\n",
    "\n",
    "# Calculate metrics for No-SMOTE model\n",
    "roc_auc_no_smote = roc_auc_score(y_test, y_proba_no_smote)\n",
    "pr_auc_no_smote = average_precision_score(y_test, y_proba_no_smote)  # AUC-PR\n",
    "accuracy_no_smote = accuracy_score(y_test, y_pred_no_smote)\n",
    "average_precision_no_smote = average_precision_score(y_test, y_proba_no_smote)\n",
    "\n",
    "# Print comparison results\n",
    "print(\"Metrics Comparison on Test Data:\")\n",
    "print(\"\\nWith SMOTE + L2:\")\n",
    "print(f\"AUC-ROC: {roc_auc_smote:.4f}\")\n",
    "print(f\"AUC-PR: {pr_auc_smote:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_smote:.4f}\")\n",
    "print(f\"Average Precision Score: {average_precision_smote:.4f}\")\n",
    "\n",
    "print(\"\\nWithout SMOTE + L2:\")\n",
    "print(f\"AUC-ROC: {roc_auc_no_smote:.4f}\")\n",
    "print(f\"AUC-PR: {pr_auc_no_smote:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_no_smote:.4f}\")\n",
    "print(f\"Average Precision Score: {average_precision_no_smote:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
